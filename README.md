# tasks-ui
CSS - Cascading Style Sheets


Type of selectors
Universal (*)
Elemenet selector (tag name)
class (.)-  meet link and i would like to keep common properties
id (#)  - single student having a unique and should be stable
grouping selector
combinators
    - Descendant Selector (space)
    - Child Selector (>)

Type of styles 
1. Inline
2. Internal
3. Common css


At ABN Amro Bank, I encountered one of the most critical incidents in my role as an engineering lead, which turned out to be both a technical and leadership challenge that left a long-term positive impact on our organization. The incident began when we received a high-priority ticket through ServiceNow. Usually, ServiceNow was the platform where user-reported or system-generated issues were tracked, triaged, and routed to the right teams. In this case, the issue looked routine on the surface but quickly escalated because it touched on one of the most sensitive areas in banking â€” customer data security. The report indicated that International Bank Account Numbers (IBANs) were being exposed in a GET API call. Now, in banking systems, exposing such sensitive information in a way that could be easily logged, cached, or intercepted was a serious privacy violation. It had compliance implications because regulators such as GDPR in Europe and internal banking policies set strict limits on how such identifiers could be displayed or transmitted. It also had reputational implications â€” if customers discovered that their IBANs were not being adequately protected, the trust they placed in the bank could be badly damaged. Because of this combination of compliance risk, security exposure, and potential customer impact, the incident was immediately tagged as high priority and escalated to the engineering team for investigation and resolution.

As the engineering lead at that time, I was responsible not just for helping debug the issue but also for coordinating the technical response, proposing a practical solution, and ensuring that the fix did not cause ripple effects in other parts of the system. My mindset in such situations was not only about patching the immediate hole but also about thinking systemically â€” how to prevent this class of issue from happening again across other services and teams. That distinction was important because, in large organizations like banks, similar patterns often exist in multiple systems. Fixing one without addressing the others is like repairing a leak in one pipe while leaving the rest of the plumbing vulnerable. I had to balance the urgency of fixing the incident with the responsibility of proposing a robust, sustainable solution that would make the system stronger in the long run. The challenge was also heightened by the fact that this was not just a simple bug. From early signs, it looked like a design issue that spanned multiple services, which meant I needed to align several engineering teams, architects, and security stakeholders, all while under the pressure of an active production incident.

The first step I took was to quickly organize a review session with the technical team handling the APIs. We pulled logs, analyzed traffic, and walked through the API specifications. During this investigation, we discovered that the problem was not isolated to one endpoint. Multiple services were exposing sensitive user information through GET calls. This meant that sensitive data, such as IBAN numbers, were appearing in URLs, which could be logged by browsers, proxies, or servers, and even cached unintentionally. From a security and compliance perspective, this was unacceptable. What made it worse was that because GET requests are commonly used for fetching data, some developers had adopted them even when sensitive parameters were involved, without realizing the risks. So, this was not only a technical issue but also a cultural one â€” an example of where development practices had drifted away from security best practices.

Once I understood the breadth of the problem, I stepped in with a clear proposal. Instead of continuing to pass sensitive information through GET requests, we would redesign those endpoints to use POST requests. POST requests are better suited for cases where sensitive data must be transmitted, because the data is carried in the request body rather than in the URL. This makes it less likely to be logged or cached unintentionally. In other words, the switch from GET to POST was not just a fix but a structural improvement that aligned our APIs with security standards and reduced exposure risk. I presented this solution to the team, explained why GET calls were dangerous in this context, and outlined how we could apply the change across services. Importantly, I framed it not just as a one-off incident response but as a governance opportunity â€” a chance to reset our API design principles.

While we worked on implementing the fix, I also took on the role of communicating with non-technical stakeholders. Incidents of this nature often create anxiety, particularly with business leaders or compliance officers who may not fully understand the technical details but do grasp the potential consequences. I scheduled a call to explain the situation in simple, non-technical terms. I used an analogy of a traffic light system: the lights themselves were working fine, but the wiring allowed some sensitive signals to leak into the open, and this misconfiguration could cause accidents. By framing it this way, I reassured stakeholders that we had identified the issue, contained the risk, and were fixing it in a way that improved the overall system. I emphasized transparency, explained what had gone wrong, what steps we were taking to fix it, and what preventive controls we would introduce to make sure it would not happen again. This style of communication helped reduce panic and maintain trust.

After fixing the immediate issue by moving the exposed GET calls to POST, we did not stop there. I proposed and implemented a series of long-term preventive measures. We introduced stricter API governance checks so that future API changes could be automatically validated against security rules. We enhanced our code review process to explicitly include security validations, ensuring that no developer could inadvertently expose sensitive data through poor endpoint design. In addition, we integrated automated validation into our CI/CD pipeline, so that potential violations would be caught earlier, before code ever reached production. By embedding these practices into our MLOps and DevOps pipelines, we made security a default part of development rather than an afterthought.

The results of this incident were positive on several levels. First, the immediate crisis was resolved quickly, preventing further exposure of sensitive IBAN data. This contained the compliance and reputational risk. Second, the client â€” in this case, the internal business stakeholders and external regulators â€” appreciated the speed of our response and the clarity of our communication. By explaining things in simple terms and being transparent about both the mistake and the fix, we built trust rather than eroding it. Third, the systemic improvements we introduced had a lasting impact. By changing design practices, introducing governance checks, and automating validation, we reduced the likelihood of similar incidents occurring in the future. This was not just a one-time firefight; it was an opportunity to raise the maturity of our engineering processes.


âœ… Thatâ€™s **\~950 words** for Part 1 (Polaris). Itâ€™s plain English, STAR-structured in flow, and ends with **impact statements** (how it helped *you, your leader, your team* â†’ boosting your Z-score).

ðŸ‘‰ Next, Iâ€™ll expand **Part 2 (Scoot Airlines, 2015)** to \~1000 words with similar style. Do you want me to continue directly, or would you like to review/edit Part 1 first before I draft Part 2?
